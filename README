Autor: Luiz Carlos A M Cavalcanti (cavalcanti.luiz@gmail.com)

Compilando e executando o programa
----------------------------------

Software necessário: 

    - Hadoop (versão 1.2.1 foi utilizada no desenvolvimento)
    - Apache Ant
    - Java 1.6 ou superior


Passo a passo:

    1) Edite o arquivo build.xml e altere o valor da propriedade "hadoop.dir" para apontar para o diretório raiz da instalação do hadoop em seu ambiente. É importante notar que esse é o diretório que deve conter o arquivo hadoop-core-<versão>.jar
    2) Execute o build através do comando "ant build.xml", pressupondo que o utilitário "ant" esteja em seu PATH e o java esteja devidamente configurado. Após a compilação, o pacote binário estará disponível em dist/frequent.jar;
    3) Edite o arquivo run.sh (Mac OS X ou Linux/Unix/BSD) a fim de ajustar as variáveis a seguir:
        a) HADOOP_BASE - Deve apontar para o diretório raiz da instalação do hadoop (mesmo valor requerido no passo 1);
        b) HFS_BASE_DIR - Diretório do sistema de arquivos distribuído onde serão criados os diretórios de entrada e saída dos dados a serem processados. O diretório deve existir previamente, podendo ser criado com o comando "hadoop dfs -mkdir /caminho/para/o/diretorio;
    4) Execute o arquivo run.sh. Talvez seja necessário atribuir permissão para execução do arquivo (chmod +x run.sh). Se o ambiente não der suporte ao bash (Windows, em muitos casos), pode-se executar os comandos manualmente, na ordem que se encontram no arquivo run.sh.